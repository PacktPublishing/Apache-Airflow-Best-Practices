{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "DATASET_LOCATION='https://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "DATASET_HASH='https://files.grouplens.org/datasets/movielens/ml-latest.zip.md5'\n",
    "dst_d = Path.cwd() / '..' / 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_lens_data(source,destination):\n",
    "    \"\"\"Downloads movie lens data\n",
    "    \"\"\"\n",
    "    dst_f = Path(destination) / Path(source).name\n",
    "    r = requests.get(source)\n",
    "    if r.ok:\n",
    "        with open(dst_f,\"wb\") as f:\n",
    "            f.write(r.content)\n",
    "    return dst_f\n",
    "\n",
    "downloaded_files = download_lens_data(DATASET_LOCATION, dst_d)\n",
    "\n",
    "def unzip_files(zipped_file,destination):\n",
    "    \"\"\"Unzips a movie lens data set file\n",
    "    \"\"\"\n",
    "    zip_dir = Path(zipped_file).stem\n",
    "    needed_files = [\"ratings.csv\", \"movies.csv\"]\n",
    "    needed_files = [ Path(zip_dir) / Path(f) for f in needed_files]\n",
    "    needed_files = [ Path(destination) / f for f in needed_files ]\n",
    "    \n",
    "    with zipfile.ZipFile(zipped_file,'r') as z:\n",
    "        z.extractall(destination)\n",
    "    return needed_files\n",
    "\n",
    "ratings, movies = unzip_files(downloaded_files, dst_d)\n",
    "[os.path.exists(f) for f in (ratings, movies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pl.read_csv(ratings)\n",
    "ratings_df.drop_in_place(\"timestamp\")\n",
    "ratings_df = ratings_df.with_columns(pl.col('movieId').rank(method=\"dense\").alias(\"movie_encoding\")-1)\n",
    "ratings_df = ratings_df.with_columns(pl.col('userId').rank(method=\"dense\").alias(\"user_encoding\")-1)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = ratings_df.n_unique(subset=[\"user_encoding\"])\n",
    "n_movies = ratings_df.n_unique(subset=[\"movie_encoding\"])\n",
    "max_rating = ratings_df['rating'].max()\n",
    "min_rating = ratings_df['rating'].min()\n",
    "\n",
    "print(n_users, n_movies, max_rating, min_rating)\n",
    "\n",
    "X = ratings_df[['user_encoding', 'movie_encoding']].to_numpy()\n",
    "y = ratings_df['rating'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=50)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]\n",
    "y_train = (y_train - min_rating)/(max_rating - min_rating)\n",
    "y_test = (y_test - min_rating)/(max_rating - min_rating)\n",
    "n_factors = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing a input layer for users\n",
    "user = tf.keras.layers.Input(shape = (1,))\n",
    "\n",
    "## Embedding layer for n_factors of users\n",
    "u = tf.keras.layers.Embedding(n_users, n_factors, embeddings_initializer = 'he_normal', embeddings_regularizer = tf.keras.regularizers.l2(1e-6))(user)\n",
    "u = tf.keras.layers.Reshape((n_factors,))(u)\n",
    "\n",
    "## Initializing a input layer for movies\n",
    "movie = tf.keras.layers.Input(shape = (1,))\n",
    "\n",
    "## Embedding layer for n_factors of movies\n",
    "m = tf.keras.layers.Embedding(n_movies, n_factors, embeddings_initializer = 'he_normal', embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(movie)\n",
    "m = tf.keras.layers.Reshape((n_factors,))(m)\n",
    "\n",
    "## stacking up both user and movie embeddings\n",
    "x = tf.keras.layers.Concatenate()([u,m])\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "## Adding a Dense layer to the architecture\n",
    "x = tf.keras.layers.Dense(32, kernel_initializer='he_normal')(x)\n",
    "x = tf.keras.layers.Activation(activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(16, kernel_initializer='he_normal')(x)\n",
    "x = tf.keras.layers.Activation(activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "## Adding an Output layer with Sigmoid activation function which gives output between 0 and 1\n",
    "x = tf.keras.layers.Dense(9)(x)\n",
    "x = tf.keras.layers.Activation(activation='softmax')(x)\n",
    "\n",
    "## Adding a Lambda layer to convert the output to rating by scaling it with the help of available rating information\n",
    "# x = tf.keras.layers.Lambda(lambda x: x*(max_rating - min_rating) + min_rating)(x)\n",
    "\n",
    "## Defining the model\n",
    "model = tf.keras.models.Model(inputs=[user,movie], outputs=x)\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005,\n",
    "    # rho=0.9, momentum=0.01, epsilon=1e-07)\n",
    "\n",
    "## Compiling the model\n",
    "\n",
    "model.compile(optimizer='sgd', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=3, min_lr=0.000001, verbose=1)\n",
    "\n",
    "history = model.fit(x = X_train_array, y = y_train, batch_size=4096, epochs=70, verbose=1, validation_data=(X_test_array, y_test)\n",
    ",shuffle=True,callbacks=[reduce_lr])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
